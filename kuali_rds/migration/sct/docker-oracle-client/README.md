## Dockerized Oracle client

A docker-container for Oracle Instant Client 12, based on CentOs. You can use this container to run any SQL script necessary against both source and target oracle databases as part of a data migration. The "source" database for a kuali migration is the one we've been using for years now since 2016. We call this the ***"legacy"*** database. The target database can be referred to as the ***"RDS"*** database.

This container is mostly for convenience and automation of many otherwise manual SQL execution steps.
The container comes with helper scripts that are environment "aware" - that is, given a "landscape" identifier (ie: sb, ci, qa, stg, prod), connection details can be obtained dynamically using lookups through the aws cli, which is also installed.

Uses include:

- Establish a sqlplus client interactive session against any of our Kuali databases either in the "legacy" vpn accessible subnets or newer private subnets associated with the common app infrastructure account.
- Run the SQL scripts generated by the AWS schema conversion tool.
- Run post data migration validation scripts

### Prerequisites:



### Use cases:

Navigate to the correct directory:

```
cd kuali-infrastructure/kuali_rds/migration/sct/docker-oracle-client
```

From here, you can run the container through a helper script.
The first time you run the container, you will see the image being built first. All subsequent calls will be more straightforward.
You can drive what the container does with name=value parameter pairs:



#### Kuali use cases:

------

   

- **Run all SCT-generated SQL scripts:**

  This is the main use case for kuali.
  If you have generated DDL scripts with AWS Schema Conversion tool, they will exist in a different input directory:
  `../sql/[landscape]`
  These scripts will be run in the order reflected by their numeric prefix *(ie: `"03.create.kcoeus.user.sql"` will be run 3rd)*.
  Run all scripts in this folder as follows: 

  ```
  # Have omitted rds parameters dynamically looked-up based on tag values that match the provided landscape:
  sh dbclient.sh run-sct-scripts \
    aws_access_key_id=[your key] \
    aws_secret_access_key=[your secret] \
    landscape=ci
    
  # or...
  
  # Explicitly provide rds parameters:
  sh dbclient.sh run-sct-scripts \
    aws_access_key_id=[your key] \
    aws_secret_access_key=[your secret] \
    landscape=stg \
    template_bucket_name=kuali-research-ec2-setup \
    db_host=kuali-oracle-stg.cnc9dm5uqxog.us-east-1.rds.amazonaws.com \
    db_user=admin \
    local_port=1521
    
  # include a "dryrun=true" parameter to see what would get run without actually invoking it.
  ```

     

- **Turn off/on all constraints and triggers**

  If you've run all the SCT generated SQL scripts, the last stage of that process disables all the constraints and triggers of the newly created RDS database. This is done so that data migration soon to follow will not encounter any problems inserting rows of data into tables. However, this means that once the data migration is finished, you will want to reinstate these constraints and triggers:

  ```
  # Disable all constraints and triggers
  # NOTE: "DISABLE" is the default for toggle_constraints and toggle_triggers, so you can omit them.
    aws_access_key_id=[your key] \
    aws_secret_access_key=[your secret] \
    landscape=ci
    
  # Enable all constraints and triggers:
  sh dbclient.sh toggle-constraints-triggers\
    aws_access_key_id=[your key] \
    aws_secret_access_key=[your secret] \
    landscape=ci \
    toggle_constraints=ENABLE toggle_triggers=ENABLE
  ```

     

- **Update sequences**
A migration that continues with [Change data capture](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Task.CDC.html) replicates all table data on an ongoing basis, but not the changes to sequences used by those tables:
   
   > *"As DMS does not replicate incremental sequence numbers during CDC from source database, you will need to generate the latest sequence value from the source for all the sequences and apply it on the target Amazon RDS for Oracle database to avoid sequence value inconsistencies."*

   When cutting over from the source database to the target RDS database, the sequences in the target database will need to be advanced so that they reflect the changes to the sequences in the source database that occurred since the original target database sequences were created using the [schema conversion tool](../sct/README.md). Use the following script to update the sequences in the target RDS database to catch them back up with and match the corresponding source database sequences:
   
   ```
   sh dbclient.sh update-sequences \
     aws_access_key_id=[your key] \
     aws_secret_access_key=[your secret] \
     aws_region=us-east-1 \
     template_bucket_name=kuali-research-ec2-setup \
  landscape=stg
   ```
   
   The prior invocation provided the aws credentials, a landscape, and the s3 bucket name where a copy of kc-config.xml is kept.
   This will allow for source and target database connection details to be looked up, based on the landscape in s3 and secrets manager.
   Alternatively, if you know the oracle connection parameters, you can provide them explicitly:
   
   ```
   # The _db_sid and _db_port parameters will default to "Kuali" and "1521" respectively if ommitted.
   # The remaining parameters are not optional.
   sh dbclient.sh update-sequences \
     legacy_db_host=buaws-kuali-db-stage001.bu.edu \
     legacy_db_user=KCOEUS \
     legacy_db_port=1521 \
     legacy_db_sid=Kuali \
     legacy_db_password=[legacy password] \
     rds_db_host=buaws-kuali-oracle-stg.cnc9dm5uqxog.us-east-1.rds.amazonaws.com \
     rds_db_user=admin \
     rds_db_port=1521 \
     rds_db_sid=Kuali \
     rds_db_password=[rds password]
   ```
   
   
   
- **Run Table row count comparison scripts:**

   After the AWS migration service has run, one way to validate that all data has been migrated is to compare table row counts between the source and target schemas. The following script will print out only the names of tables whos row counts differ between source and target schemas.
   A valid migration should lead to this script outputting no tables names.

   ```
   # EXAMPLE 3: Run ALL SQL script files in the input folder against the RDS database:
   sh dbclient.sh compare-table-counts \
     aws_access_key_id=[your key] \
     aws_secret_access_key=[your secret] \
     landscape=ci \
     bucket_name=kuali-research-ec2-setup
   ```

      

#### Generic use cases:

------

   

- **Run interactive session:**

  Start session with "Legacy" database:

   ```
   # EXAMPLE 1:
   sh dbclient.sh run \ 
     aws_access_key_id=[your key] \
     aws_secret_access_key=[your secret] \
     landscape=ci \
     legacy=true \
     bucket_name=kuali-research-ec2-setup
        
   # EXAMPLE 2: A bucket name and landscape was included above because s3 contains the kc-config.xml file, which is downloaded and parsed for connection details. However, you could provide the connection details directly as follows:
   sh dbclient.sh run \
     aws_access_key_id=[your key] \
     aws_secret_access_key=[your secret] \
     legacy=true \
     db_host=buaws-kuali-db-ci001.bu.edu \
     db_port=1521 \
     db_user=KCOEUS \
     db_password=[password] \
     db_sid=Kuali
   ```

  ​    

   Start session with"Target" RDS database:

   ```
   # EXAMPLE 1: 
   sh dbclient.sh run \ 
     aws_access_key_id=[your key] \
     aws_secret_access_key=[your secret] \
     landscape=ci
   
   # EXAMPLE 2: (If you know the RDS db password or it's not stored in secrets manager)
   sh dbclient.sh run \ 
     aws_access_key_id=[your key] \
     aws_secret_access_key=[your secret] \
     db_password=[password] \
     landscape=ci
   ```
  
  
     Example output:
  
     ```
     LANDSCAPE=ci
     TEMPLATE_BUCKET_NAME=kuali-research-ec2-setup
     Using default aws profile
     {
         "RequestId": "68a23ff0-3b39-47c8-888c-9f96c6448610",
         "Success": true
     }
     Establishing SSH Tunnel: jumpbox host using ssm start-session to access rds endpoint
     Warning: Permanently added 'i-0aaceb74fb9621cae' (ECDSA) to the list of known hosts.
     bind [::1]:5432: Cannot assign requested address
      
     Tunnel established.
        
     SQL*Plus: Release 18.0.0.0.0 - Production on Wed Sep 2 22:54:35 2020
     Version 18.3.0.0.0
        
     Copyright (c) 1982, 2018, Oracle.  All rights reserved.
        
     Last Successful login time: Wed Sep 02 2020 22:12:20 +00:00
        
     Connected to:
     Oracle Database 19c Standard Edition 2 Release 19.0.0.0.0 - Production
     Version 19.7.0.0.0
        
     SQL> 
     ```
  
  
     You can start running SQL commands or scripts:
  
     ```
     SQL> describe account
     Name                                      Null?    Type
     ----------------------------------------- -------- ----------------------------
     CODE                                      NOT NULL NUMBER(12)
     ACCOUNT_NUMBER                            NOT NULL VARCHAR2(16)
     DESCRIPTION                                        VARCHAR2(200)
     UPDATE_USER                               NOT NULL VARCHAR2(60)
     UPDATE_TIMESTAMP                          NOT NULL DATE
     VER_NBR                                   NOT NULL NUMBER(8)
     OBJ_ID                                    NOT NULL VARCHAR2(36)
     ACTV_IND                                           CHAR(1)
     
     SQL>
     ```
  
  
     And quit:
  
     ```
     SQL> exit
     Disconnected from Oracle Database 19c Standard Edition 2 Release 19.0.0.0.0 - Production
     Version 19.7.0.0.0
     ```
  
     
  
- **Run one, multiple, or all SQL script files:**

   You can run selected SQL files against the database.

   - Create an `"input"` subdirectory in the same folder as dbclient.sh if it does not already exist.
      All SQL script files that you want to run should be placed in this folder.
   - The names of the files you want to run should be provided as a comma delimited list (no spaces) as a `"file_to_run"` parameter
   - The output of each file will appear in it's own log file in an `"output"` folder *(will be created on the fly if it does not already exist)*.

   ```
   # EXAMPLE 1: Run 3 SQL scripts against the legacy database:
   sh dbclient.sh run \
     aws_access_key_id=[your key] \
     aws_secret_access_key=[your secret] \
     landscape=ci \
     legacy=true \
     bucket_name=kuali-research-ec2-setup \
     files_to_run=test3.sql,test2.sql,test1.sql
     
   # EXAMPLE 2: Run 1 SQL script against the RDS database:
   sh dbclient.sh run \
     aws_access_key_id=[your key] \
     aws_secret_access_key=[your secret] \
     landscape=ci \
     files_to_run=test2.sql
     
   # EXAMPLE 3: Run ALL SQL script files in the input folder against the RDS database:
   sh dbclient.sh run \
     aws_access_key_id=[your key] \
     aws_secret_access_key=[your secret] \
     landscape=ci \
     files_to_run=all
   ```

      

- **Run raw sql:**
  If the sql is short, you could provide it inline like this:

   ```
  sh dbclient.sh run \
     aws_access_key_id=[your key] \
     aws_secret_access_key=[your secret] \
     landscape=ci \
     raw_sql="select table_name from user_tables;"
   ```

  ​    

- More