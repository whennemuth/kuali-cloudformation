# NOTES:
#   EC2:
#     image_name: amzn-ami-2018.03.a-amazon-ecs-optimized
#     os: Amazon Linux
#     ecs_runtime_version: Docker version 17.12.1-ce
#     ecs_agent_version: 1.18.0
#    
#     The mappings included in this template are for the latest ECS optimized AMIs as of June 2018.
#     They only include those AMIs for US regions. To query for the latest AMI per region, use the 
#     following command in the aws CLI:
#       aws ssm get-parameters --names /aws/service/ecs/optimized-ami/amazon-linux/recommended/image_id --region [REGION]
#     where REGION is us-east-1, us-west-2, etc.

#   AUTO-SCALING:
#     In this template we define EC2 auto-scaling as distinct from application auto-scaling employed 
#     by the service(s) for ECS. The difference is that EC2 auto-scaling uses properties like MinSize,
#     MaxSize, DesiredCapacity, etc. to refer to the number of EC2 instances need to run in order to 
#     meet targets for metric thresholds. ECS auto-scaling uses these properties to refer to docker 
#     containers (tasks) and how many of them should be running across the ECS cluster (can span one 
#     or more EC2 instances) to meet targets for metric thresholds. Combined, these two auto-scaling 
#     types define the overall auto-scaling strategy. This implies a certain amount of orchestration
#     to make sure the two types collaborate with each other instead of clash.
#     SEE: https://www.reddit.com/r/aws/comments/5swd80/ec2_vs_ecs_autoscaling_question/

#   AUTO_SCALING-GROUP:
#     The ECSContainerInstanceAutoScalingGroup resource will not go into a CREATE_COMPLETE state until 
#     enough EC2 instances are heard back from to say they are running. The userdata defined to run on 
#     EC2 startup will call the cfn-signal function that comes packaged in the aws optimized ami to signal 
#     that the instance is running. We are requiring that a minimum of 1 such signals are received by 
#     setting the ECSContainerInstanceAutoScalingGroup.CreationPolicy.ResourceSignal.Count property. 
#     Currently the signal is sent upon startup, but it could be made contingent on further conditions 
#     written into the EC2 userdata, like a test that a task(s) is running must also succeed (you could 
#     send more than one signal and up CreationPolicy.ResourceSignal.Count property correspondingly).
 
#   AMI_MAPPINGS:
#     TODO: In order to not have to maintain and ami mapping (see below), delegate ami lookup to a lambda 
#     function:
#       https://github.com/awsdocs/aws-cloudformation-user-guide/blob/master/doc_source/walkthrough-custom-resources-lambda-lookup-amiids.md

#   CONTENT_FROM_S3_BUCKET:
#     Typically to place files where they need to go, you would declare their content inline using 
#     AWS::CloudFormation::Init.file.[filename].content. However, you can use the 
#     AWS::CloudFormation::Init.file.[filename].source instead and specify a file in an S3 bucket. Example here:
#       https://aws.amazon.com/blogs/devops/authenticated-file-downloads-with-cloudformation/

#   USERDATA_VS_CFN-INIT:
#     UserData is run only once upon creation of the ec2 instance and will call cfn-init for the first time as 
#     one of its last commands. Instead of being procedural like UserData, cfn-init is state-based in that it 
#     comprises only commands that deposit/replace files, set environment variables, update packages, etc. But 
#     the biggest difference is that cfn-init can be run again after the initial ec2 creation either by modifying
#     anything in the AWS::CloudFormation::Init resource of the cfn stack template and performing a stack update, 
#     or shelling into the ec2 instance and running:
# 
#       /opt/aws/bin/cfn-init \
#         -v --region ${AWS::Region} \
#         --stack ${AWS::StackName} \
#         --resource YourResourceName \
#         --configsets ...
#
#     If you make a modification to UserData cloudformation will REPLACE that EC2 instance during a stack update.
#     If you make a modification to AWS::CloudFormation::Init, cloudformation will UPDATE that ec2 instance in place 
#     during a stack update. So, rule of thumb: Don't put anything in UserData that you want to be "refreshable" 
#     with a stack update

AWSTemplateFormatVersion: 2010-09-09

Description: >
  Deploys an ECS cluster to the specified VPC and subnets using an auto scaling group.


Parameters:

  Landscape:
    Description: Specify which landscape to build into the VPC
    Type: String
    AllowedValues:
    - sb
    - ci
    - qa
    - stg
    - prod
    ConstraintDescription: >
      This parameter is restricted to the following values: sb, ci, qa, stg, prod
    Default: sb

  EC2InstanceType:
    Type: String
    Description: What type of EC2 instance should be used for hosting?
    AllowedValues:
    - t2.small
    - t2.medium
    - t2.large
    - t2.xlarge
    - t3.small
    - t3.medium
    - t3.large
    - t3.xlarge
    - m4.large
    - m4.xlarge
    - m5.large
    - m5.xlarge
    ConstraintDescription: Specified instance type is not within selection list.
    Default: m4.large

  GlobalPrefix:
    Type: String
    Description: > 
      A common value that all resources in this template will prefix to
      their name to establish a bundling through naming convention. If a nested stack,
      this will most likely be the name of the top-most stack.
    Default: ECS-test

  vpcid:
    Type: AWS::EC2::VPC::Id
    Description: The id of the vpc this is a subnet of.

  ClusterSize:
    Type: Number
    Description: How many EC2 instances are to be initially deployed as ECS hosts?
    AllowedValues: [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ]
    ConstraintDescription: Cluster size is limited between 1 and 10 instances.
    Default: 2

  LoadBalancerUrl:
    Type: String
    Description: The public DNS address at which apps can be reached

  Subnets:
    Type: List<AWS::EC2::Subnet::Id>
    Description: The subnets this cluster should span.

  SecurityGroup:
    Type: AWS::EC2::SecurityGroup::Id
    Description: The security group to use for ECS cluster hosts.

  BucketName:
    Type: String
    Description: The S3 bucket where our config files, keys, etc. are stored
    Default: kuali-research-ec2-setup

  EnableNewRelicInfrastructure:
    Type: String
    Description: Is newrelic infrastructure (with logging) to be enabled for this landscape?
    Default: "false"
    AllowedValues:
    - "true"
    - "false"
    ConstraintDescription: Enter "true" or "false" only.
    Default: "false"


Resources:

  Utils:
    Type: AWS::CloudFormation::Stack
    Properties:
      TemplateURL: 
        !Sub https://s3.amazonaws.com/${BucketName}/cloudformation/lambda/ami-lookup.yaml
      Parameters:
        GlobalPrefix:
          !Ref GlobalPrefix

  AMIInfo:
    Type: Custom::AMIInfo
    Properties:
      ServiceToken:
        !GetAtt Utils.Outputs.AMIInfoFunctionArn
      Region:
        Ref: AWS::Region    

  ECSCluster:
    Type: AWS::ECS::Cluster
    Properties:
      ClusterName:
        !Join [ "-", [ !Ref GlobalPrefix, "ecs-cluster" ] ]

  ECSContainerInstanceAutoScalingGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    DependsOn: ECSCluster
    Description: The auto scaling group where the number of ec2 instances are scaled up or down.
    Properties:
      VPCZoneIdentifier:
        !Ref Subnets
      LaunchConfigurationName:
        !Ref ECSLaunchConfiguration
      MaxSize: 10
      MinSize: 1
      DesiredCapacity:
        !Ref ClusterSize
      Tags:
      - Key: Name
        Value:
          !Sub "${GlobalPrefix}-${Landscape}-${AWS::StackName}-auto-scaling-group"
        PropagateAtLaunch: true
    CreationPolicy:
      ResourceSignal:
        Count: 1
        Timeout: PT5M
    UpdatePolicy:
      AutoScalingRollingUpdate:
        MinInstancesInService: 1
        MaxBatchSize: 1
        WaitOnResourceSignals: true
        PauseTime: PT10M
        SuspendProcesses:
        - HealthCheck
        - ReplaceUnhealthy
        - AZRebalance
        - AlarmNotification
        - ScheduledActions

  ECSContainerInstanceScaleUpPolicy:
    Type: AWS::AutoScaling::ScalingPolicy
    Properties:
      AutoScalingGroupName:
        !Ref ECSContainerInstanceAutoScalingGroup
      AdjustmentType: ChangeInCapacity
      Cooldown: 60
      EstimatedInstanceWarmup: 30
      MetricAggregationType: Average
      ScalingAdjustment: 1
      PolicyType: SimpleScaling

  ECSContainerInstanceScaleDownPolicy:
    Type: AWS::AutoScaling::ScalingPolicy
    Properties:
      AutoScalingGroupName:
        !Ref ECSContainerInstanceAutoScalingGroup
      AdjustmentType: ChangeInCapacity
      Cooldown: 60
      MetricAggregationType: Average
      ScalingAdjustment: -1

  ECSContainerInstanceScaleUpAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmDescription: Scale-up if Memory consumption >= 80% for 10 minutes
      MetricName: MemoryUtilization
      Namespace: AWS/EC2
      ComparisonOperator: GreaterThanOrEqualToThreshold
      EvaluationPeriods: 10
      Period: 60
      Statistic: Average
      Threshold: 80

  ECSLaunchConfiguration:
    Type: AWS::AutoScaling::LaunchConfiguration
    Properties:
      ImageId:
        !GetAtt AMIInfo.Id
        # !FindInMap [ RegionMap, !Ref 'AWS::Region', AMI ]
      EC2InstanceType:
        !Ref EC2InstanceType
      SecurityGroups:
      - !Ref SecurityGroup
      IamInstanceProfile:
        !Ref ECSInstanceProfile
      BlockDeviceMappings:
        - DeviceName: /dev/xvda
          Ebs:
            VolumeSize: 64
            DeleteOnTermination: true
            
      UserData: 
        "Fn::Base64": !Sub |
          #!/bin/bash
          yum install -y https://s3.amazonaws.com/ec2-downloads-windows/SSMAgent/latest/linux_amd64/amazon-ssm-agent.rpm
          yum install -y aws-cfn-bootstrap
          yum install -y git
          # Add perl and zip libraries needed to unpack and run custom metric monitoring for cloudwatch.
          yum install -y perl-Switch perl-DateTime perl-Sys-Syslog perl-LWP-Protocol-https perl-Digest-SHA.x86_64
          yum install -y zip unzip
          yum install -y sysstat
          yum install -y jq
          
          # Modify the sudoers file so that anyone in the wheel group can be a sudoer
          chmod u+w /etc/sudoers && \
          echo -e "%wheel\tALL=(ALL)\tNOPASSWD: ALL" >> /etc/sudoers && \
          chmod u-w /etc/sudoers && \
          
          # NOTE: Creating users here and not in Metadata.AWS::CloudFormation::Init.config.users due to restrictions: 
          # Users are created as non-interactive system users with a shell of /sbin/nologin. This is by design and cannot be modified.
          for user in wrh mukadder dhaywood mkousheh ; do
              adduser -m $user && \
              usermod -aG root $user && \
              usermod -aG docker $user && \
              usermod -aG wheel $user && \
              mkdir /home/$user/.ssh && \
              chmod 700 /home/$user/.ssh && \
              chown -R $user:$user /home/$user
          done
          
          # Install required packages for scripts that will monitor and upload custom metrics to cloudwatch.
          curl https://aws-cloudwatch.s3.amazonaws.com/downloads/CloudWatchMonitoringScripts-1.2.2.zip \
            -o /var/lib/ && CloudWatchMonitoringScripts-1.2.2.zip
          unzip -d /var/lib/ CloudWatchMonitoringScripts-1.2.2.zip
          rm -f /var/lib/CloudWatchMonitoringScripts-1.2.2.zip
          
          # Implement all the metadata in AWS::CloudFormation::Init
          /opt/aws/bin/cfn-init \
              -v \
              --configsets AllConfigs \
              --region ${AWS::Region} \
              --stack ${AWS::StackName} \
              --resource ECSLaunchConfiguration
          
          # Now that all initialization is done signal success
          /opt/aws/bin/cfn-signal \
              -e $? \
              --region ${AWS::Region} \
              --stack ${AWS::StackName} \
              --resource ECSContainerInstanceAutoScalingGroup
    Metadata:
      # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-init.html
      # 1) If your template calls the cfn-init script, the script looks for resource
      #    metadata rooted in the AWS::CloudFormation::Init metadata key.
      # 2) The cfn-hup helper is a daemon that detects changes in resource metadata
      #    and runs user-specified actions when a change is detected.
      #    This allows you to make configuration updates on your running Amazon
      #    EC2 instances through the UpdateStack API action
      # 3) The user actions that the cfn-hup daemon calls periodically are defined
      #    in the hooks.conf configuration file.
      #    To support composition of several applications deploying change notification
      #    hooks, cfn-hup supports a directory named hooks.d that 
      #    is located in the hooks configuration directory. You can place one
      #    or more additional hooks configuration files in the hooks.d directory.
      #    The additional hooks files must use the same layout as the hooks.conf file.
      # 4) services.sysvinit.servicename.files: A list of files. If cfn-init
      #    changes one directly via the files block, this service will be restarted.'
      # 5) The cfn-init helper script processes these configuration sections
      #    in the following order: packages, groups, users, sources, files, commands, '
      #    and then services. If you require a different order, separate your
      #    sections into different config keys, and then use a configset that 
      #    specifies the order in which the config keys should be processed.
      
      AWS::CloudFormation::Authentication:
        S3AccessCreds:
          type: S3
          roleName:
            !Ref ECSRole
          buckets:
          - !Ref BucketName

      AWS::CloudFormation::Init:
        configSets:
          AllConfigs:
          - getFiles
          - ConfigSet: RunCommands
          GetFiles:
          - getFiles
          RunCommands:
          - ConfigSet: cmd01
          - ConfigSet: cmd02
          - ConfigSet: cmd03
          - ConfigSet: cmd04
          cmd01:
          - 01_get_configs_from_s3
          cmd02:
          - 02_create_env_exports_file
          cmd03:
          - 03_add_instance_to_cluster
          cmd04:
          - 04_start_cron_for_custom_cloudwatch_metrics

        getFiles:
          packages:
            yum:
              awslogs: []
          files:
            /home/wrh/.ssh/authorized_keys:
              mode: "000600"
              owner: wrh
              group: wrh
              source:
                !Sub https://s3.amazonaws.com/${BucketName}/ecs/ssh-keys/rsa-key-wrh.pub
            /home/mkousheh/.ssh/authorized_keys:
              mode: "000600"
              owner: mkousheh
              group: mkousheh
              source:
                !Sub https://s3.amazonaws.com/${BucketName}/ecs/ssh-keys/rsa-key-mkousheh.pub
            /home/mukadder/.ssh/authorized_keys:
              mode: "000600"
              owner: mukadder
              group: mukadder
              source:
                !Sub https://s3.amazonaws.com/${BucketName}/ecs/ssh-keys/rsa-key-mukadder.pub
            /home/dhaywood/.ssh/authorized_keys:
              mode: "000600"
              owner: dhaywood
              group: dhaywood
              source:
                !Sub https://s3.amazonaws.com/${BucketName}/ecs/ssh-keys/rsa-key-dhaywood.pub
            /opt/kuali/README.txt:
              content: !Sub |
                This directory contains the "environment" for each app to run
                in a docker container that it needs.
                This includes env-file, configuration files, keys, etc.
                These are specific to the ${Landscape} landscape.
              mode: "000775"
              owner: root
              group: root
            /root/.ssh/git_rsa_key:
              mode: "000600"
              owner: root
              group: root
              source:
                !Sub https://s3.amazonaws.com/${BucketName}/bu_github_id_docker_rsa
            /opt/kuali/scripts/crontab:
              content: |
                SHELL=/bin/bash
                PATH=/sbin:/bin:/usr/sbin:/usr/bin
                MAILTO=root
                HOME=/
                
                # Send custom metrics to cloudwatch once every minute
                # NOTE: The cronjob will start, but it does nothing until you uncomment the 1 or more of the 3 lines below.
                # This is a test ec2 instance, so defaulting to running these scripts manually while shelled in."
                # Check the system log for any errors this script encounters"
                # * * * * * /opt/kuali/scripts/send-custom-cloudwatch-metrics1.sh
                # * * * * * /opt/kuali/scripts/send-custom-cloudwatch-metrics2.sh
                # * * * * * /opt/kuali/scripts/send-psuedo-cloudwatch-metrics.sh
                #
                0 3 * * * /bin/bash /opt/kuali/scripts/stopinstance.sh
              mode: "000644"
              owner: root
              group: root
            /opt/kuali/scripts/send-custom-cloudwatch-metrics1.sh:
              content: |
                #!/bin/bash
                # Adding additional cloudwatch metrics that include memory utilization.
                # See: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html
                /var/lib/aws-scripts-mon/mon-put-instance-data.pl \
                  --mem-used-incl-cache-buff \
                  --mem-util \
                  --mem-avail \
                  --disk-space-util \
                  --disk-path=/ \
                  --from-cron             
              mode: "000744"
              owner: root
              group: root
            /opt/kuali/scripts/send-custom-cloudwatch-metrics2.sh:
              content: |
                #!/bin/bash
                # Cloudwatch metrics alternative that include are custom and cover all needed measurments.
                # Use this method as a replacement for the mon-put-instance-data.pl approach.
                # See: https://aws.amazon.com/premiumsupport/knowledge-center/cloudwatch-custom-metrics/
                export AWS_DEFAULT_REGION=us-east-1
                INSTANCEID=$(curl http://169.254.169.254/latest/meta-data/instance-id)
                USEDMEMORY_PERCENT=$(free -m | awk 'NR==2{printf "%.2f\t", $3*100/$2 }')
                USEDDISK_PERCENT=$(df / | awk 'NR==2{print $5}' | sed 's/\%//g')
                TCP_CONN=$(netstat -an | wc -l)
                TCP_CONN_PORT_80=$(netstat -an | grep 80 | wc -l)
                USERS=$(uptime | awk '{ print $4 }')
                IO_WAIT_PERCENT=$(iostat | awk 'NR==4 {print $4}')
                  # If no average cpu record, then take the cpu as of this moment
                [ -z "$((cat /tmp/average.cpu | grep -P '^\d+(\.\d+)?$') 2> /dev/null)" ] && grep 'cpu ' /proc/stat | awk '{print ($2+$4)*100/($2+$4+$5)}' > /tmp/average.cpu
                AVERAGE_CPU=$(cat /tmp/average.cpu)
                  # Compute the average cpu utilization by taking a reading every 2 seconds for 58 seconds and taking their average.
                  # The cron job is on a minute schedule, so 58 seconds will ensure that a new average will be recorded BEFORE the next cron cycle.
                NEXT_AVERAGE_CPU=$(n=0 && cat <(echo "$(while [ $n -lt 4 ] ; do grep 'cpu ' /proc/stat && sleep 2 && n=$((n+1)) ; done)") | awk '{c++; t += ($2+$4)*100/($2+$4+$5)} END {print t/c}')
                echo $NEXT_AVERAGE_CPU > /tmp/average.cpu
                
                aws cloudwatch put-metric-data --dimensions Instance=$INSTANCEID --namespace "ECSTestCustomMetrics" --metric-name cpu-usage --value $AVERAGE_CPU
                aws cloudwatch put-metric-data --dimensions Instance=$INSTANCEID --namespace "ECSTestCustomMetrics" --metric-name memory-usage --value $USEDMEMORY_PERCENT
                aws cloudwatch put-metric-data --dimensions Instance=$INSTANCEID --namespace "ECSTestCustomMetrics" --metric-name disk-usage --value $USEDDISK_PERCENT
                aws cloudwatch put-metric-data --dimensions Instance=$INSTANCEID --namespace "ECSTestCustomMetrics" --metric-name tcp_connections --value $TCP_CONN
                aws cloudwatch put-metric-data --dimensions Instance=$INSTANCEID --namespace "ECSTestCustomMetrics" --metric-name tcp_connection_on_port_80 --value $TCP_CONN_PORT_80
                aws cloudwatch put-metric-data --dimensions Instance=$INSTANCEID --namespace "ECSTestCustomMetrics" --metric-name nbr_of_users --value $USERS
                aws cloudwatch put-metric-data --dimensions Instance=$INSTANCEID --namespace "ECSTestCustomMetrics" --metric-name io_wait --value $IO_WAIT_PERCENT
              mode: "000744"
              owner: root
              group: root
            /opt/kuali/scripts/send-psuedo-cloudwatch-metrics.sh:
              content: !Sub |
                #!/bin/bash

                # This function streams a json file from s3 that indicates dummy metrics to send to cloudwatch.
                # The purpose is to simulate higher (or lower) thresholds that would trigger alarms to engage
                # a scale-in or scale-out policy for auto-scaling activity.
                  sendDummyMetrics() {
                    # local json=$(cat /c/whennemuth/workspaces/ecs_workspace/dummy-metrics/dummy-ecs-metrics.json)
                    local json=$(aws s3 cp s3://${BucketName}/dummydata/dummy-ecs-metrics.json)
                    local namespace=$(echo "$json" | jq -r '.Namespace')
                    local instances=$(echo $json | jq -r -c '.Instances[]')
                    local evals=()
                    while read -r instance; do
                      local instanceId=$(echo "$instance" | jq -r '.InstanceId')
                      local metrics=$(echo $instance | jq -r -c '.Metrics[]')
                      while read -r metric; do
                        local name=$(echo "$metric" | jq -r '.MetricName')
                        local baseline=$(echo "$metric" | jq -r '.BaselineValue')
                        local deviation=$(echo "$metric" | jq -r '.DeviationValue')
                        # Examples to set until to a value offset from current UTC time
                        # date +%s --date='+5 minute'
                        # date +%s --date='-1 hour'
                        local until=$(echo "$metric" | jq -r '.DeviateUntil')
                        local value=$baseline
                        local now=$(date +%s)
                        [ $until -gt $now ] && value=$deviation
                        local evalstr="$(cat <<EOF
                          aws cloudwatch put-metric-data \
                          --region ${AWS::Region} \
                            --dimensions Instance=$instanceId \
                            --namespace "$namespace" \
                            --metric-name $name \
                            --value $value
                  EOF
                        )"
                      evals=("${!evals[@]}" "$(echo "$evalstr" | sed -E 's/[[:space:]]+/ /g' | xargs)")
                      done <<< "$metrics"
                    done <<< "$instances"
                  
                  for cmd in "${!evals[@]}" ; do
                      echo "$cmd"
                      eval "$cmd"
                    done
                  }
                  
                  sendDummyMetrics
              mode: "000744"
              owner: root
              group: root
            /etc/cfn/cfn-hup.conf:
              mode: "000400"
              owner: root
              group: root
              content: !Sub |
                [main]
                stack=${AWS::StackId}
                region=${AWS::Region} 
                # Change interval from default 15 minutes to 5
                interval=5
            /etc/cfn/hooks.d/cfn-auto-reloader.conf:
              content: !Sub |
                [cfn-auto-reloader-hook]
                triggers=post.update
                path=Resources.ECSLaunchConfiguration.Metadata.AWS::CloudFormation::Init
                action=/opt/aws/bin/cfn-init -v --region ${AWS::Region} --stack ${AWS::StackName} --resource ECSLaunchConfiguration 
            /etc/awslogs/awscli.conf:
              content: !Sub |
                [plugins]
                cwlogs = cwlogs
                [default]
                region = ${AWS::Region}
            /etc/awslogs/awslogs.conf:
              content: !Sub |
                [general]
                state_file = /var/lib/awslogs/agent-state
                
                [/var/log/dmesg]
                file = /var/log/dmesg
                log_group_name = ${GlobalPrefix}-${Landscape}-${ECSCluster}
                log_stream_name = /var/log/dmesg
                
                [/var/log/messages]
                file = /var/log/messages
                log_group_name = ${GlobalPrefix}-${Landscape}-${ECSCluster}
                log_stream_name = /var/log/messages
                datetime_format = %b %d %H:%M:%S
                
                [/var/log/docker]
                file = /var/log/docker
                log_group_name = ${GlobalPrefix}-${Landscape}-${ECSCluster}-docker
                log_stream_name = /var/log/docker
                datetime_format = %Y-%m-%dT%H:%M:%S.%f
                
                [/var/log/ecs/ecs-init.log]
                file = /var/log/ecs/ecs-init.log.*
                log_group_name = ${GlobalPrefix}-${Landscape}-${ECSCluster}-ecs
                log_stream_name = /var/log/ecs/ecs-init.log
                datetime_format = %Y-%m-%dT%H:%M:%SZ
                
                [/var/log/ecs/ecs-agent.log]
                file = /var/log/ecs/ecs-agent.log.*
                log_group_name = ${GlobalPrefix}-${Landscape}-${ECSCluster}-ecs
                log_stream_name = /var/log/ecs/ecs-agent.log
                datetime_format = %Y-%m-%dT%H:%M:%SZ
                
                [/var/log/ecs/audit.log]
                file = /var/log/ecs/audit.log.*
                log_group_name = ${GlobalPrefix}-${Landscape}-${ECSCluster}-ecs
                log_stream_name = /var/log/ecs/audit.log
                datetime_format = %Y-%m-%dT%H:%M:%SZ
            /opt/kuali/scripts/s3.download.configs.sh:
              content: !Sub |
                #!/bin/bash
                echo "Downloading all configurations for containers from the s3 bucket, landscape ${!LANDSCAPE}"
                
                [ ! -d /opt/kuali/s3 ] && mkdir -p /opt/kuali/s3
                cd /opt/kuali/s3
                aws s3 sync --delete \
                  --exclude "*" \
                  --include "core/*" \
                  --include "portal/*" \
                  --include "pdf/*" \
                  --include "kuali/main/config/kc-config-rds.xml" \
                  s3://${BucketName}/${!LANDSCAPE}/ .
                mv /opt/kuali/s3/kuali/main/config/kc-config-rds.xml /opt/kuali/s3/kuali/main/config/kc-config.xml
                aws s3 cp s3://${BucketName}/rice.cer /opt/kuali/s3/kuali/main/config/
                aws s3 cp s3://${BucketName}/rice.keystore /opt/kuali/s3/kuali/main/config/
              mode: "000775"
              owner: root
              group: root
            /opt/kuali/scripts/process.env.file.sh:
              content: |
                #!/bin/bash
                # Turn a name=value line into an "export name='value'" line
                getLineExport() {
                  local line=$(echo -n "$1" | xargs) # Use xargs to trim the line.
                  # Return an empty string if the line is a properties file comment
                  [ "${line:0:1}" == "#" ] && echo "" && exit 0;
                  [ -z "$line" ] && echo "" && exit 0;
                  if [ -n "$(echo $testline | grep -P '\x22')" ] ; then
                    echo "export $line"
                  else
                    # Put double quotes around the exported variable value
                    echo "export $(echo $line | sed 's/=/="/1')\""
                  fi
                }
                
                # Create a script to export all environment variables in the mounted directory before starting node
                createExportFile() {
                  local ENV_FILE_FROM_S3="$1"
                if [ ! -f $ENV_FILE_FROM_S3 ] ; then
                  echo "ERROR! MISSING $ENV_FILE_FROM_S3"
                    exit 1
                  else
                    cd $(dirname $ENV_FILE_FROM_S3)
                    rm -f export.sh
                    echo "Creating $(pwd)/export.sh..."
                    while read line ; do
                      expline="$(getLineExport "$line")" 
                      [ -z "$expline" ] && continue
                      prop=$(echo "$line" | cut -f1 -d '=')
                      # Override some of the existing environment variables
                      [ "${prop^^}" == "SHIB_HOST" ] && expline="export SHIB_HOST="
                      [ "${prop^^}" == "ROOT_DIR" ]  && expline="export ROOT_DIR=/var/core-temp"
                      echo "Setting env var $prop" 
                      echo "$expline" >> export.sh
                    done < $ENV_FILE_FROM_S3
                    # In case the file from s3 originated on a windows file system, remove return carriage chars
                    sed -i 's/\r//g' export.sh
                  fi
                }

                for f in $(env | grep 'ENV_FILE_FROM_S3') ; do
                  envfile="$(echo $f | cut -d'=' -f2)"
                  # Replace the standard kuali-research-[env].bu.edu references with the dns address of this instances load balancer.
                  sed -i -r "s/kuali-research.*.bu.edu/$LOAD_BALANCER_URL/g" "$envfile"
                  # Create the export.sh file
                  createExportFile "$envfile"
                done
                  
                exit 0
              mode: "000775"
              owner: root
              group: root
        01_get_configs_from_s3:
          commands:
            cmd01:
              cwd: /opt/kuali/scripts
              env:
                LANDSCAPE: !Sub "${Landscape}"
              command: bash s3.download.configs.sh
        02_create_env_exports_file:
          commands:
            cmd01:
              cwd: /opt/kuali/scripts
              env:
                ENV_FILE_FROM_S3_CORE: /opt/kuali/s3/core/environment.variables.s3
                ENV_FILE_FROM_S3_PORTAL: /opt/kuali/s3/portal/environment.variables.s3
                ENV_FILE_FROM_S3_PDF: /opt/kuali/s3/pdf/environment.variables.s3
                LOAD_BALANCER_URL: "${LoadBalancerUrl}"
              command: bash process.env.file.sh
        03_add_instance_to_cluster:
          commands:
            cmd01:
              command:
                !Sub echo ECS_CLUSTER=${ECSCluster} >> /etc/ecs/ecs.config
          services:
            sysvinit:
              cfn-hup:
                enabled: true
                ensureRunning: true
                files:
                - /etc/cfn/cfn-hup.conf
                - /etc/cfn/hooks.d/cfn-auto-reloader.conf
              # awslogs:
              # NOTE: If you are using Amazon Linux 2, the awslogs service is now called "awslogsd"
              awslogsd:
                enabled: true
                ensureRunning: true
                files:
                - /etc/awslogs/awslogs.conf
                - /etc/awslogs/awscli.conf
        04_start_cron_for_custom_cloudwatch_metrics:
          commands:
            cmd01:
              command: crontab -u root /opt/kuali/scripts/crontab
              env:
                LANDSCAPE: !Sub "${Landscape}"
  ECSRole:
    Type: AWS::IAM::Role
    Description: >
      This IAM Role is attached to all of the ECS hosts. Add other IAM
      policy statements here to allow access from your ECS hosts to other AWS services.
      This role will be used by ALL containers running on the ECS host.
    Properties:
      Path: "/"
      RoleName:
        !Sub "${GlobalPrefix}-ECSRole-${Landscape}-${AWS::Region}"
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
      ManagedPolicyArns:
      - arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM
      Policies:
      - PolicyName:
          !Sub "${GlobalPrefix}-${Landscape}-ecs-service-policy"
        PolicyDocument:
          Statement:
          - Effect: Allow
            Resource: "*"
            Action:
            - ecs:CreateCluster
            - ecs:DeregisterContainerInstance
            - ecs:DiscoverPollEndpoint
            - ecs:Poll
            - ecs:RegisterContainerInstance
            - ecs:StartTelemetrySession
            - ecs:Submit*
            - logs:CreateLogStream
            - logs:PutLogEvents
            - ecr:BatchCheckLayerAvailability
            - ecr:BatchGetImage
            - ecr:GetDownloadUrlForLayer
            - ecr:GetAuthorizationToken
            - ec2messages:AcknowledgeMessage
            - ec2messages:DeleteMessage
            - ec2messages:FailMessage
            - ec2messages:GetEndpoint
            - ec2messages:GetMessages
            - ec2messages:SendReply
            - cloudwatch:PutMetricData
            - cloudwatch:GetMetricStatistics
            - cloudwatch:ListMetrics
            - ec2:DescribeInstanceStatus
            - ec2:DescribeTags
            - ds:CreateComputer
            - ds:DescribeDirectories
            - logs:CreateLogGroup
            - logs:CreateLogStream
            - logs:DescribeLogGroups
            - logs:DescribeLogStreams
            - logs:PutLogEvents
            - s3:PutObject
            - s3:GetObject
            - s3:AbortMultipartUpload
            - s3:ListMultipartUploadParts
            - s3:ListBucket
            - s3:ListBucketMultipartUploads
  ECSInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      InstanceProfileName: Profile-for-ECS-Role
      Path: "/"
      Roles:
      - !Ref ECSRole
  ECSContainerInstanceAutoScalingRole:
    Type: AWS::IAM::Role
    Properties:
      Path: "/"
      RoleName:
        !Sub "${GlobalPrefix}-ECS-Autoscale-Role-${Landscape}-${AWS::Region}"
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - application-autoscaling.amazonaws.com
      Policies:
      - PolicyName:
          !Sub "${GlobalPrefix}-${Landscape}-ecs-autoscale-service-policy"
        PolicyDocument:
          Statement:
          - Effect: Allow
            Resource: "*"
            Action:
            - application-autoscaling:*
            - cloudwatch:DescribeAlarms
            - cloudwatch:PutMetricAlarm
            - ecs:DescribeServices
            - ecs:UpdateService
Outputs:
  Cluster:
    Description: A reference to the ECS cluster
    Value:
      !Ref ECSCluster
  ECSContainerInstanceAutoScalingRole:
    Description: A reference to ECS service auto scaling role
    Value:
      !GetAtt ECSContainerInstanceAutoScalingRole.Arn
  ECSContainerInstanceAutoScalingGroupName:
    Description: A reference to ECS AutoScaling Group Name
    Value:
      !Ref ECSContainerInstanceAutoScalingGroup
